{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 09 - Machine Learning with Scikit-learn\n",
        "\n",
        "# Srija Velumula"
      ],
      "metadata": {
        "id": "HEXyE6VAqiNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n",
        "\n",
        "Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence.\n",
        "\n",
        "# Answer\n",
        "\n",
        "Logistic: Train accuracy 0.7333, Test accuracy 0.718\n",
        "\n",
        "Null: Train accuracy 0.6467, Test accuracy 0.608\n",
        "\n",
        "Logistic_L1_C_1: Train accuracy 0.732, Test accuracy 0.716\n",
        "\n",
        "Logistic_L1_C_01: Train accuracy 0.726, Test accuracy 0.706\n",
        "\n",
        "Logistic_L1_C_10: Train accuracy 0.7347, Test accuracy 0.718\n",
        "\n",
        "Logistic_L1_C_auto: Train accuracy 0.7233, Test accuracy 0.708\n",
        "\n",
        "Logistic_SL1_C_auto: Train accuracy 0.7307, Test accuracy 0.714\n",
        "\n",
        "RandomForest_noCV: Train accuracy 0.9993, Test accuracy 0.686\n",
        "\n",
        "The optimal model selection would be a model which maintains balanced training and test accuracy performance while avoiding overfitting. The RandomForest_noCV model demonstrates severe overfitting because it reaches almost perfect training accuracy (0.9993) yet its test accuracy (0.686) remains low indicating poor generalization.\n",
        "The Logistic_L1_C_10 model (Logistic Regression with L1 penalty and C=10) demonstrated the best performance by achieving a test accuracy of 0.718 which was identical to the base Logistic model while also reaching a training accuracy of 0.7347. The model demonstrates an optimal relationship between complexity and generalization capabilities. The base Logistic model demonstrated equivalent test accuracy (0.718) as the other models.\n",
        "The standard Logistic model and Logistic_L1_C_10 demonstrate the highest test accuracy while Logistic_L1_C_10 exhibits a slightly superior training accuracy performance. The model achieved better performance with L1 regularization when C=10 was applied as a weak penalty term without compromising generalization capabilities.\n",
        "\n"
      ],
      "metadata": {
        "id": "7o4oBQnhqma7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 and 3\n",
        "\n",
        "\n",
        "Next, fit a series of logistic regression models, without regularization. Each model should use the same set of predictors (all of the relevant predictors in the dataset) and should use the entire dataset, rather than a fraction of it. Use a randomly chosen 80% proportion of observations for training and the remaining for checking the generalizable performance (i.e., performance on the holdout subset). Be sure to ensure that the training and holdout subsets are identical across all models. Each model should choose a different solver.\n",
        "\n",
        "Compare the results of the models in terms of their accuracy (use this as the performance metric to assess generalizability error on the holdout subset) and the time taken (use appropriate timing function). Summarize your results via a table with the following structure:\n",
        "\n",
        "\n",
        "Solver used\n",
        "\n",
        "Training subset accuracy\n",
        "\n",
        "Holdout subset accuracy\n",
        "\n",
        "Time taken"
      ],
      "metadata": {
        "id": "xRtCNYSHqquK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from patsy import dmatrices\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "GtyNBQsLrTg-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T6Ab9IPXjuiq"
      },
      "outputs": [],
      "source": [
        "df_patient = pd.read_csv('PatientAnalyticFile.csv')\n",
        "\n",
        "# Create mortality variable\n",
        "df_patient['mortality'] = np.where(df_patient['DateOfDeath'].isnull(), 0, 1)\n",
        "\n",
        "# Calculate age\n",
        "df_patient['DateOfBirth'] = pd.to_datetime(df_patient['DateOfBirth'])\n",
        "df_patient['Age_years'] = ((pd.to_datetime('2015-01-01') - df_patient['DateOfBirth']).dt.days/365.25)\n",
        "\n",
        "# Create formula for all variables in model\n",
        "vars_remove = ['PatientID', 'First_Appointment_Date', 'DateOfBirth',\n",
        "               'Last_Appointment_Date', 'DateOfDeath', 'mortality']\n",
        "vars_left = set(df_patient.columns) - set(vars_remove)\n",
        "formula = \"mortality ~ \" + \" + \".join(vars_left)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y, X = dmatrices(formula, df_patient)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, np.ravel(Y),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# List of solvers to evaluate\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']"
      ],
      "metadata": {
        "id": "XvknESZsrWAh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_solver(solver_name, X_train, X_test, y_train, y_test):\n",
        "    start_time = time.time()\n",
        "\n",
        "    if solver_name == 'liblinear':\n",
        "        model = LogisticRegression(solver=solver_name, penalty='l2', random_state=42)\n",
        "    elif solver_name == 'sag' or solver_name == 'saga':\n",
        "        model = LogisticRegression(solver=solver_name, penalty=None, random_state=42, max_iter=1000)\n",
        "    else:\n",
        "        model = LogisticRegression(solver=solver_name, penalty=None, random_state=42)\n",
        "\n",
        "    # Fit model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate time\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracies\n",
        "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "    return {\n",
        "        'Solver': solver_name,\n",
        "        'Training Accuracy': train_accuracy,\n",
        "        'Holdout Accuracy': test_accuracy,\n",
        "        'Time Taken (seconds)': elapsed_time\n",
        "    }\n"
      ],
      "metadata": {
        "id": "FdGXBROgrYL0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for solver in solvers:\n",
        "    result = evaluate_solver(solver, X_train, X_test, y_train, y_test)\n",
        "    results.append(result)\n",
        "\n",
        "# Create and display results table\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df[['Solver', 'Training Accuracy', 'Holdout Accuracy', 'Time Taken (seconds)']]\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7BE69RdraOG",
        "outputId": "eb28b38b-686b-4538-9ce5-c768402c7452"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Solver  Training Accuracy  Holdout Accuracy  Time Taken (seconds)\n",
            "newton-cg           0.748062           0.73550              0.098839\n",
            "    lbfgs           0.748125           0.73575              0.204017\n",
            "liblinear           0.747938           0.73625              0.062977\n",
            "      sag           0.747938           0.73575              2.989801\n",
            "     saga           0.748000           0.73600              5.766594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4\n",
        "\n",
        "Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\n",
        "\n",
        "\n",
        "The accuracy results from running all solvers show minimal variations between each other. The training accuracy measurement between the best solver lbfgs at 0.748125 and the worst solvers liblinear and sag at 0.747938 shows a minor difference of 0.00075. The highest holdout accuracy of 0.73625 belongs to liblinear while newton-cg shows the lowest at 0.73550 which represents a 0.00075 difference between them.\n",
        "The execution time shows significant variations between different solvers. The liblinear solver executed the task in 0.062977 seconds which provided 1.6 times speed advantage over newton-cg and 3.2 times speed advantage over lbfgs and 47.5 times speed advantage over sag and 91.6 times speed advantage over saga.\n",
        "I recommend liblinear as the top solver solution for this dataset and task based on the obtained results. The decision was made through multiple metrics but execution time proved decisive because accuracy levels were similar. The efficient choice for this task becomes liblinear because it delivered the maximum holdout accuracy (0.73625) within the lowest computational time (0.062977 seconds).\n",
        "Liblinear would remain our first choice even when accuracy becomes the only important factor since it demonstrates slightly better holdout accuracy performance. Practical machine learning applications require finding equilibrium between accuracy and efficiency because large datasets and frequent model training sessions demand it.\n",
        "Newton-cg stands as my preferred choice for its efficient speed and accuracy level and lbfgs follows behind it in performance ranking based on time-accuracy considerations."
      ],
      "metadata": {
        "id": "YIwGXyQmqseC"
      }
    }
  ]
}